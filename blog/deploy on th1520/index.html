<!doctype html>
<html lang="en" dir="ltr" class="blog-wrapper blog-post-page plugin-blog plugin-id-default">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.2.0">
<title data-rh="true">How to Deploy a Neural Network on TH1520 | SHL</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://csi-nn2.opensource.alibaba.com/blog/deploy on th1520"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docusaurus_tag" content="default"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docsearch:docusaurus_tag" content="default"><meta data-rh="true" property="og:title" content="How to Deploy a Neural Network on TH1520 | SHL"><meta data-rh="true" name="description" content="Introduction"><meta data-rh="true" property="og:description" content="Introduction"><meta data-rh="true" property="og:type" content="article"><meta data-rh="true" property="article:published_time" content="2023-01-11T00:00:00.000Z"><meta data-rh="true" property="article:author" content="https://github.com/zhangwm-pt"><meta data-rh="true" property="article:tag" content="TH1520,C910,NPU,Wujian600"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://csi-nn2.opensource.alibaba.com/blog/deploy on th1520"><link data-rh="true" rel="alternate" href="https://csi-nn2.opensource.alibaba.com/blog/deploy on th1520" hreflang="en"><link data-rh="true" rel="alternate" href="https://csi-nn2.opensource.alibaba.com/zh/blog/deploy on th1520" hreflang="zh"><link data-rh="true" rel="alternate" href="https://csi-nn2.opensource.alibaba.com/blog/deploy on th1520" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="SHL RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="SHL Atom Feed">



<meta name="aes-config" content="pid=xux-opensource&amp;user_type=101&amp;uid=&amp;username=&amp;dim10=csi-nn2"><link rel="stylesheet" href="/assets/css/styles.53758859.css">
<link rel="preload" href="/assets/js/runtime~main.ab91f17f.js" as="script">
<link rel="preload" href="/assets/js/main.a61364e7.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script>
<script src="//g.alicdn.com/alilog/mlog/aplus_v2.js" id="beacon-aplus" exparams="clog=o&amp;aplus&amp;sidx=aplusSidx&amp;ckx=aplusCkx"></script>
<script src="//g.alicdn.com/aes/??tracker/1.0.34/index.js,tracker-plugin-pv/2.4.5/index.js,tracker-plugin-event/1.2.5/index.js,tracker-plugin-jserror/1.0.13/index.js,tracker-plugin-api/1.1.14/index.js,tracker-plugin-perf/1.1.8/index.js,tracker-plugin-eventTiming/1.0.4/index.js"></script><div id="__docusaurus">
<div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#docusaurus_skipToContent_fallback">Skip to main content</a></div><nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo.svg" alt="My Site Logo" class="themedImage_ToTc themedImage--light_HNdA"><img src="/img/logo.svg" alt="My Site Logo" class="themedImage_ToTc themedImage--dark_i4oU"></div><b class="navbar__title text--truncate">SHL</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/blog">Blog</a></div><div class="navbar__items navbar__items--right"><div class="navbar__item dropdown dropdown--hoverable dropdown--right"><a href="#" aria-haspopup="true" aria-expanded="false" role="button" class="navbar__link"><svg viewBox="0 0 24 24" width="20" height="20" aria-hidden="true" class="iconLanguage_nlXk"><path fill="currentColor" d="M12.87 15.07l-2.54-2.51.03-.03c1.74-1.94 2.98-4.17 3.71-6.53H17V4h-7V2H8v2H1v1.99h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11.76-2.04zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2l-4.5-12zm-2.62 7l1.62-4.33L19.12 17h-3.24z"></path></svg>English</a><ul class="dropdown__menu"><li><a href="/blog/deploy on th1520" target="_self" rel="noopener noreferrer" class="dropdown__link dropdown__link--active" lang="en">English</a></li><li><a href="/zh/blog/deploy on th1520" target="_self" rel="noopener noreferrer" class="dropdown__link" lang="zh">简体中文</a></li></ul></div><a href="https://github.com/T-head-Semi/csi-nn2" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="searchBox_ZlJk"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="container margin-vert--lg"><div class="row"><aside class="col col--3"><nav class="sidebar_re4s thin-scrollbar" aria-label="Blog recent posts navigation"><div class="sidebarItemTitle_pO2u margin-bottom--md">Recent posts</div><ul class="sidebarItemList_Yudw clean-list"><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/RVM example">RISC-V matrix extension example</a></li><li class="sidebarItem__DBe"><a aria-current="page" class="sidebarItemLink_mo7H sidebarItemLinkActive_I1ZP" href="/blog/deploy on th1520">How to Deploy a Neural Network on TH1520</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/C908 accelerates AI">XuanTie C908 Accelerates AI with Software and Hardware Fusion</a></li><li class="sidebarItem__DBe"><a class="sidebarItemLink_mo7H" href="/blog/MLPerf Tiny">XuanTie C906 Tops MLPerf Tiny v0.7 Benchmark</a></li></ul></nav></aside><main class="col col--7" itemscope="" itemtype="http://schema.org/Blog"><article itemprop="blogPost" itemscope="" itemtype="http://schema.org/BlogPosting"><header><h1 class="title_f1Hy" itemprop="headline">How to Deploy a Neural Network on TH1520</h1><div class="container_mt6G margin-vert--md"><time datetime="2023-01-11T00:00:00.000Z" itemprop="datePublished">January 11, 2023</time> · <!-- -->7 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_Hf19"><div class="avatar margin-bottom--sm"><a href="https://github.com/zhangwm-pt" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo" src="https://github.com/zhangwm-pt.png" alt="Wenmeng Zhang"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://github.com/zhangwm-pt" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Wenmeng Zhang</span></a></div><small class="avatar__subtitle" itemprop="description">Engineer @ T-Head</small></div></div></div></div></header><div id="post-content" class="markdown" itemprop="articleBody"><h2 class="anchor anchorWithStickyNavbar_LWe7" id="introduction">Introduction<a class="hash-link" href="#introduction" title="Direct link to heading">​</a></h2><p>T-Head has recently introduced a high-performance SoC prototyping, i.e. TH1520, which is built on the Wujian600 chip development platform. With a quad-core XuanTie C910 CPU withbuilt-in 4-TOPS NPU, TH1520 engenders a new combination of CPU and AI computing. </p><p>In this blog, we will describe the process of how to deploy a neural network model on C910 and on C910 and NPU simultaneously.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="tools">Tools<a class="hash-link" href="#tools" title="Direct link to heading">​</a></h2><p>T-Head offers two open-source deployment tools that enable seamless, highly efficient integration of NN frameworks and underlying hardware:</p><ul><li>Heterogeneous Honey Badge)(HHB): It supports models from different NN frameworks, and provides quantization and graph optimization.</li><li>Structure of Heterogeneous Library (SHL): It is a common interface that is compatible with all hardware types, whil offering a reference schedule that facilitates software portability.</li></ul><p><img loading="lazy" alt="Tool flow" src="/assets/images/ali135-b3fcec4e8dbd3972a20aafcc21b3cde0.png" width="880" height="524" class="img_ev3q"></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="hhb">HHB<a class="hash-link" href="#hhb" title="Direct link to heading">​</a></h3><p><a href="https://www.xrvm.com/tool-details?id=4056748601592913921#Download" target="_blank" rel="noopener noreferrer">HHB</a> is a collection of tools provided by T-Head to deploy neural network models on XuanTie processors. These tools can be incorporated for compilation, profiling, and simulation. </p><p>Its framework is based on Apache TVM, which is an end-to-end machine learning compiler structure. We have shared the source code on <a href="https://github.com/T-head-Semi/tvm" target="_blank" rel="noopener noreferrer">GitHub</a>.</p><p>HHB supports models such as Caffe, TensorFlow, ONNX, and TensorFlow Lite. It can convert these models into unified intermediate expressions for graphing performance optimization.</p><p>In addition, HHB supports multiple quantization methods to handle various data types. This framework can automatically provide the optimal scheme for the specified XuanTie CPU platform. After quantization, HHB generates a graph structure in C code from the intermediate expression. Each node of the graph structure is constructed by calling the CSI-NN2 API.</p><p>Here is an example to use HHB in deploying MobileNet model on TH1520. The sample code shows the hhb command to compile the model:</p><div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">hhb -C --board light --calibrate-dataset ./cat.jpg --model-file ./mobilenetv1.prototxt ./mobilenetv1.caffemodel --data-mean </span><span class="token string" style="color:#e3116c">&quot;103.94 116.98 123.68&quot;</span><span class="token plain"> --data-scale </span><span class="token number" style="color:#36acaa">0.007843</span><span class="token plain"> --output </span><span class="token builtin class-name">.</span><span class="token plain"> --quantization-scheme</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&quot;int8_asym&quot;</span><span class="token plain"> --pixel-format BGR</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>The following content describes the parameter options:</p><ul><li>C: specifies to execute the main command until C code is generated.</li><li>board: emphasizes as the destination platform; light is an alias of TH1520.</li><li>calibrate-dataset: specifies the calibration image used for quantization.</li><li>model-file: specifies a MobileNet model downloaded to the current directory. A Caffe model is divided into two files. The files following the option are not sequence-sensitive.</li><li>data-mean: defines a mean.</li><li>data-scale: defines a scale.</li><li>output: describes the current directory as the path to store files that you need to generate.</li><li>quantization-scheme: identifies a quantization scheme. </li><li>pixel-format: identifies the input image format required by the model training.</li></ul><p>After the command is executed, multiple files such as main.c and model.c are generated in the current directory:</p><ul><li>main.c: the reference entry to the sample program.</li><li>model.c: a model structure file that describes the model.</li><li>hhb.hm: the weights converted to int8.</li><li>io.c: the helper function for reading and writing files.</li><li>io.h: the declaration of the helper function for above files.</li><li>process.c: the image preprocessing function.</li><li>process.h: the declaration of the above function.</li></ul><p>After the HHB command generates code, the gcc command performs binary encoding.</p><div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">riscv64-unknown-linux-gnu-gcc -O0 -g3 -march</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">rv64gcv0p7_zfh_xtheadc -mabi</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">lp64d -I/home -I/home/install_nn2/include -I/home/decode/install/include -o c_runtime  main.c model.c io.c process.c -L/home/install_nn2/lib -L/home/decode/install/lib/rv -ljpeg -lpng -lz -lstdc++ -lshl_rvv -lm -static -Wl,--gc-sections</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>The following content describes the parameter options:</p><ul><li>O0 -g3: specifies the optimization option. In this example, you can use the debug-level O0 only.</li><li>march: identifies the architecture option for C910.</li><li>mabi: identifies the application binary interface (ABI) option for C910.</li><li>I: describes the location of the header file that is used during compilation.</li><li>o: describes the name of the executable file needed to generate.</li><li>main.c model.c io.c process.c: the source file yu for compilation.</li><li>L: specifies the path to store the specified library.</li><li>ljpeg: links to a JPEG decoding library.</li><li>lpng: links to a PNG decoding library.</li><li>lz: links to a zlib.</li><li>lstdc++: links to a standard C++ library.</li><li>lshl_rvv: links to an optimized version library of C910 in SHL.</li><li>lm: links to a standard math library.</li><li>static: a static link.</li><li>Wl,–gc-sections: recycles unused sections during linking.</li></ul><p>After the compilation is complete, the c_runtime file is created under the current directory. Copy the hhb.bm file and the cat.jpg image that are generated by incorporating the hhb command and the c_runtime file to the development board of C910 to execute at a time:</p><div class="language-shell codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-shell codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">./c_runtime hhb.bm cat.jpg</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>You can view the top 5 execution results on the terminal. </p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="shl">SHL<a class="hash-link" href="#shl" title="Direct link to heading">​</a></h3><p>SHL, previously called CSI-NN2,  is a neural network acceleration library.</p><p>It abstracts various common neural network operators to form unified interfaces. SHL also implements an acceleration library for XuanTie CPU. This interface offers optimization code at the assembly level for the RISC-V Vector extension. The acceleration library has adapted to multiple data types of quantization schemes.</p><p>Combined with the automatic quantization function of HHB, SHL can quickly change the original model from the single-precision floating-point data type to optimal. As a result,the model can deliver the best performance on the development board.</p><p>The source code of SHL has been made available on <a href="https://github.com/T-head-Semi/csi-nn2" target="_blank" rel="noopener noreferrer">GitHub</a>.</p><p>SHL shares the specifications of RISCV-V Vector extension V0.7.1 in the implementation of the neural network operator on XuanTie C910. Considering the features of the CPU hardware (such as pipeline dependence, branch prediction, or cache), SHL fully excavates the parallel capabilities of the fp16 data format in the algorithm.</p><p>To balance performance and accuracy, some SoCs may have an NPU to accelerate some int8 neural network operators. SHL provides one reference schedule module to find the best processor for  operators.</p><p><img loading="lazy" alt="graph opt" src="/assets/images/ali136-73a2f322deb96fd8df1252539baab274.png" width="1202" height="610" class="img_ev3q"></p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="c910-performance">C910 Performance<a class="hash-link" href="#c910-performance" title="Direct link to heading">​</a></h2><p>XuanTie C910 is a 64-bit high-performance processor based on the 64-bit RISC-V architecture. This processor adopts a state-of-the-art 12-stage and out-of-order multiple issue superscalar pipeline. On TH1520, it can clock up to 2.5GHz. It is also equipped with 128-bit vector operation units to deliver optimized performance. </p><p>The vector operation units of XuanTie C910 are designed following version 0.7.1 of RISC-V Vector Extension. C910 supports wide-ranging data formats, including int8, int16, int32, int64, bf16, fp16, fp32, and fp64. fp16 is the default format for deploying network models, with which Xuantie C910 can achieve its best performance.</p><p>We have tested various typical image classification models. The table below presents the performance of our deployment software on C910 at 1.85 GHz.</p><p><img loading="lazy" alt="c910 perf" src="/assets/images/ali138-2ba85047243dc356868ada350815adcd.png" width="1238" height="406" class="img_ev3q"></p><p>As a comparison, <a href="https://github.com/google/XNNPACK" target="_blank" rel="noopener noreferrer">XNNPACK</a> costs 77ms (multi-threaded) to infer a MobileNet model on Raspberry Pi 4B.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="c910-and-npu">C910 and NPU<a class="hash-link" href="#c910-and-npu" title="Direct link to heading">​</a></h2><p>In order to accelerate the convolution operator in the neural network, TH1520 is equipped with a 4-TOPS NPU. The NPU can also expedite more than 20 other operators in the neural network under int8.</p><p>The table below presents the performance of combining C910 and NPU to access typical image classification models:</p><p><img loading="lazy" alt="npu perf" src="/assets/images/ali139-ee83d8b897492361bbc070ea55945ac9.png" width="1178" height="320" class="img_ev3q"></p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="conclusion">Conclusion<a class="hash-link" href="#conclusion" title="Direct link to heading">​</a></h2><p>This article describes in details on how to deploy a neural network model on TH1520, We have also presented optimal performance of TH1520 in basic image classification tasks.</p><p>TH1520 has already been incorporated inside Alibaba’s ecosystem, which demonstrates the feasibility of RISC-V-based high-performance devices to deploy neural network models. In addition, the source code of deployment tools, HHB and SHL, has been open-sourced and shared on GitHub.</p><p><a href="https://www.xrvm.com/" target="_blank" rel="noopener noreferrer">Read more details related to the hardware and software.</a></p></div><footer class="row docusaurus-mt-lg blogPostFooterDetailsFull_mRVl"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/th-1520">TH1520</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/c-910">C910</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/npu">NPU</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/blog/tags/wujian-600">Wujian600</a></li></ul></div><div class="col margin-top--sm"><a href="https://github.com/alibaba-open-source-website/easyexcel/tree/main/blog/2023-01-11-deploy-on-th1520/index.md" target="_blank" rel="noreferrer noopener" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Blog post page navigation"><a class="pagination-nav__link pagination-nav__link--prev" href="/blog/RVM example"><div class="pagination-nav__sublabel">Newer Post</div><div class="pagination-nav__label">RISC-V matrix extension example</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/blog/C908 accelerates AI"><div class="pagination-nav__sublabel">Older Post</div><div class="pagination-nav__label">XuanTie C908 Accelerates AI with Software and Hardware Fusion</div></a></nav></main><div class="col col--2"><div class="tableOfContents_bqdL thin-scrollbar"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#introduction" class="table-of-contents__link toc-highlight">Introduction</a></li><li><a href="#tools" class="table-of-contents__link toc-highlight">Tools</a><ul><li><a href="#hhb" class="table-of-contents__link toc-highlight">HHB</a></li><li><a href="#shl" class="table-of-contents__link toc-highlight">SHL</a></li></ul></li><li><a href="#c910-performance" class="table-of-contents__link toc-highlight">C910 Performance</a></li><li><a href="#c910-and-npu" class="table-of-contents__link toc-highlight">C910 and NPU</a></li><li><a href="#conclusion" class="table-of-contents__link toc-highlight">Conclusion</a></li></ul></div></div></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Docs</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://www.yuque.com/za4k4z/kkzsw9/cs7ms4" target="_blank" rel="noopener noreferrer" class="footer__link-item">Tutorial</a></li></ul></div><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://xrvm.com/" target="_blank" rel="noopener noreferrer" class="footer__link-item">T-HEAD Open Chip Community<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/blog">Blog</a></li><li class="footer__item"><a href="https://github.com/T-head-Semi/csi-nn2" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2023 T-Head, Inc. Built with Docusaurus.</div></div></div></footer></div>
<script src="/assets/js/runtime~main.ab91f17f.js"></script>
<script src="/assets/js/main.a61364e7.js"></script>
</body>
</html>